

 opt: 

cnn_optim_beta: 0.999
finetune_cnn_after: -1
batch_size: 16
val_images_use: 933
optim_epsilon: 1e-08
input_encoding_size: 256
losses_log_every: 25
id: 1529521904-both
optim_beta: 0.999
input_h5: /scratch/ayachnes/Clarity-Workspace/NeuralTalk2-Android/data-both.h5
rnn_size: 256
beam_size: 7
cnn_optim_alpha: 0.8
language_eval: 0
seed: 123
optim: adam
gpuid: 1
cnn_model: model/VGG_ILSVRC_16_layers.caffemodel
drop_prob_lm: 0.6
grad_clip: 0.1
cnn_weight_decay: 0
save_checkpoint_every: 200
learning_rate_decay_every: 100
cnn_proto: model/VGG_ILSVRC_16_layers_deploy.prototxt
save_cp: 0
input_json: /scratch/ayachnes/Clarity-Workspace/NeuralTalk2-Android/data-both.json
seq_per_img: 5
cnn_learning_rate: 1.5e-07
preprotype: both
cnn_optim: adam
max_iters: 8000
checkpoint_path: 
start_from: 
learning_rate: 0.0001
learning_rate_decay_start: 400
backend: cudnn
csv_out: 
optim_alpha: 0.8


Successfully loaded model/VGG_ILSVRC_16_layers.caffemodel
conv1_1: 64 3 3 3
conv1_2: 64 64 3 3
conv2_1: 128 64 3 3
conv2_2: 128 128 3 3
conv3_1: 256 128 3 3
conv3_2: 256 256 3 3
conv3_3: 256 256 3 3
conv4_1: 512 256 3 3
conv4_2: 512 512 3 3
conv4_3: 512 512 3 3
conv5_1: 512 512 3 3
conv5_2: 512 512 3 3
conv5_3: 512 512 3 3
fc6: 1 1 25088 4096
fc7: 1 1 4096 4096
fc8: 1 1 4096 1000



************************** Iteration 0      total_loss: 7.521246 **************************


validation loss: 7.5070831492316

**********************************************************************************************




************************** Iteration 200      total_loss: 4.621483 **************************


validation loss: 4.5204992834201

**********************************************************************************************

